Title: 用于轻量级图像超分辨率的CNN和Transformer混合网络

Abstract：
  问题：近年来许多基于CNN的方法在单图像超分辨率方面取得了巨大进展；然而这些现有的架构通常构建大量的网络层，带来了高计算复杂度和高内存消耗
  解决：提出了一种CNN和Transformer的混合网络HNCT，用于轻量级图像超分辨率。
  HNCT由由四个部分组成“浅特征提取模块”“CNN和Transformer混合块”“密集特征融合模块”“上采样模块”
  通过结合CNN和Transformer，HBCT同时考虑局部和非局部先验来提取有利于超分辨率重建的深层特征，同时具有足够的轻量级和灵活性
  增强的空间注意被引入到HBCT来更好地提取特征
  大量的实验表明HNCT很好
  
Introduction：
  SR用途广泛
  CNN方法大放异彩
  CNN方法需要爆炸式的计算成本和内存消耗，而且只能处理图像的局部区域，受制于卷积运算的有限内核大小，无法在长程依赖性建模上实现令人满意的效率
  Transformer出现，SwinIR取得了最先进的效果
  我们提出了一种轻量级SR模型，即CNN和Transformer的混合网络（HNCT），将CNN和Transform器集成在一起，同时对局部和非局部先验进行建模。
  具体而言，HNCT由四部分组成：浅层特征提取（SFE）模块、CNN和Transformer的混合块（HBCT）、密集特征融合（DFF）模块和上采样模块。
  首先，在浅层特征提取模块中，仅通过一个卷积层提取包含低频信息的浅层特征。然后，使用四个HBCT来提取层次特征。
  每个HBCT都包含一个Swin Transformer块（STB），内部有两个Swin变压器层、一个卷积层和两个增强空间注意力（ESA）模块[24]。
  然后，将HBCT产生的这些分层特征进行级联和融合，以获得SFE中的残余特征。
  Contribution：
    提出了一种用于图像超分辨率的CNN和Transformer的轻量级混合网络HNCT，以更少的参数实现了更好的SR性能
    提出了一种CNN和Transformer的混合快HBCT，同时利用局部和非局部先验来提取有利于超分辨率的特征
    
Method：
  Network Stucture:
    所提出了HNCT由四部分组成：浅层特征提取（SFE），CNN和Transformer混合块（HBCT）、密集特征融合（DFF）和上采样模块
    对于给定的LR图像ILR,首先使用一层卷积层来提取浅层特征F0，然后使用几个HBCT对F0进行深层特征提取
    所有HBCT的输出被Concat并发送到DFF模块，DFF模块包括两个堆叠的卷积层以融合所有层次特征，并添加全局残差学习策略以减轻学习维度。1*1卷积用于特征融合，3*3卷积进行进一步的特征提取
    最后上采样模块由3*3卷积和pixel shuffle层组成，重建ISR图像
  Hybrid Block of CNN and Transformer：
    HBCT由一个Swin Transformer Block、一个3*3卷积层和两个增强空间注意力模块ESA组成
    STB的提出是因为它可以极大地提高模型的表示能力。ESA的特点是重量轻、效率高
    第d-1个HBCT输出的特征图被送到第d个HBCT模块
    对于输入，HBCT首先通过ESA模块选择重要特征，然后通过STB模块提取中间特征，通过一个3*3卷积层以确保我们的网络的平移等方差，最后引入另一个ESA模块来获得更感兴趣的区域的特征
  Swin Transformer Block(STB)：
    STL采用了基于标准多头自注意的原始Transformer层架构，并引入了局部注意力和移位窗口机制
    在我们的模型中，一个STB包括两个STL来平衡性能和网络复杂性
  Enhanced Spatial Attention(ESA)
    对于给定的输入，ESA首先通过1*1卷积提取紧凑特征，减小嵌入尺寸
    接着通过一个3*3卷积，最大池化层，一个三个3*3卷积组成的卷积组和一个双线性插值实现的上采样函数
    跨卷积层和最大池化层都降低了空间维度，之后通过上采样层恢复
    
    
    
    
    
