标题：局部上下文自适应卷积核与全局谐波偏置的全色锐化算法

摘要： 大多数全色锐化方法都是基于具有标准卷积操作的卷积神经网络CNN，但是很少有人尝试上下文自适应/动态卷积。
本文提出了新策略来生成局部上下文自适应（LCA）卷积核，并引入了一种新的全局谐波（GH）偏置机制，利用图像的局部特异性并集成全局信息
提出的LAGConv可以取代上下文无关的标准卷积，以充分感知遥感全色锐化任务中每个像素的特殊性。提供了一种图像融合网络架构。

Introduction：CNN方法提高了全色锐化任务的效果。但是标准卷积固有地受到其空间不变性的限制，在记录不同对象的不同位置使用统一的卷积核可能会导致图像内容自适应能力有限
              为了应对这个问题，许多自适应卷积技术被设计来动态生成不同区域或像素的卷积核。但是现有的自适应卷积方法要么只关注小区域的局部性，要么关注完整图像而导致不希望的冗余或忽略图像细节
              本文提出了新的自适应卷积计算，由局部上下文自适应卷积核LCA和全局谐波GH偏置组成。可以充分提取和利用所涉及的图像/特征的局部和全局信息，以获得优异的性能
              Contributions：
                提出了一种基于每个像素及其邻居生成LCA卷积核的新策略，在继承了标准卷积的优点的同时增强了关注局部特征的能力，克服了上下文不可知的限制
                引入GH偏置机制，将全局信息补充到局部信息中，从而减轻空间不连续性引起的细微失真，使网络更加灵活，实现全局和局部关系之间的平衡
                用LCA和GH的组合代替标准卷积层，采用残差块的结构设计了一个简单的网络
                实验结果
                
Related Works and Motivations
  自适应卷积技术：
    适应性接收场：尺度自适应地卷积方法，目的是获得可变大小的感受野
    学习每个例子的专用卷积核：条件参数化的卷积，动态卷积
    空间自适应卷积核：通过使用不同的网络分支在每个像素学习一个独立的内核，会导致大量参数
  Motivations：
    保留了标准的空间共享卷积核，并根据局部内容估计它们的自适应权重
    为了不忽视全局信息，设计了一种全局谐波偏置机制，从而将全局和局部特征的表示集成到卷积模块中，以取代标准卷积

Proposed Method
  LAGCONV：
    在保留标准卷积核的同时，动态学习每个像素的权重，最终通过标准卷积核与权重的点积实现自适应卷积。
  标准卷积：
    对于每个1*1*Cin的像素，其局部补丁定义为k*k*Cin，k是patch size。操作期间所有输入特征图的局部补丁使用相同的内核K，K是Cin*k*k*Cout，可以看作是有Cout个卷积核，每层是k*k*Cin。结果是1*1*Cout。Cout是输出特征图的通道
  局部上下文自适应内核：
    与标准卷积不同的是，LAGConv的内核是根据局部补丁自动调整的。当Aij被输入进行卷积操作时，首先与RELU激活函数一起被送入卷积层，产生浅层特征
    接着，浅层特征被送到具有RELU和sigmoid激活函数的全连接层。学习权重Wij，大小为1*k^2, 可以感知中心像素Iij和邻居之间的潜在关系
    最后，Wij被reshape为k*k，用作K中每个核的缩放因子，与K点积后得到关于Aij的卷积核
  全局谐波偏置机制：
    这种机制的目的是对输出的特征图施加一个整体连续性
    首先，输入特征I通过全局平均池化层GAP得到~I，大小为1*Cin，然后~I被送入具有RELU激活函数的全连接层以获得输出D
    该机制允许LAGCONV产生考虑所有像素的相关输出
  
  局部上下文自适应残差网络：
    基于LAGCONV构建了一个局部上下文自适应残差块来形成整体网络，其与原始ResBlock完全相同，只是ResBlock中的标准卷积被LAGCONV取代。总共分为3步
    第一步包含LAGCONV层和RELU层，接着是几个堆叠的LCA-ResBlock，最后同样是一个LAGCONV层
    HR和上采样的LR被连接在一起以获得包含两个输入图像的特征图M，M被输入到网络
    最后将网络的输出添加到上采样的LR中以获得最终的SR图像
    算法使用MSE来作为损失函数
    
Experiments
  使用了WV3、GF2和QB数据集，应用了Wald协议。PAN大小为64*64,MS大小为16*16，训练/验证/测试数据集比例为7:2:1
  质量评估以Reduced resolution和Full resolution进行。
